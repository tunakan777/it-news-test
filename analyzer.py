import json
from janome.tokenizer import Tokenizer
from collections import Counter
import re

def load_json(filename="hatena_ranking.json"):
    """
    JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
    """
    try:
        with open(filename, "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {filename} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return []
    except json.JSONDecodeError:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {filename} ã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“")
        return []

def extract_keywords(articles):
    """
    è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰åè©ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
    """
    tokenizer = Tokenizer()
    keywords = []
    
    # ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ï¼ˆé™¤å¤–ã™ã‚‹å˜èªï¼‰- å¼·åŒ–ç‰ˆ
    stop_words = {
        # ä¸€èˆ¬çš„ãªèª
        "ã“ã¨", "ã“ã‚Œ", "ãã‚Œ", "ã‚‚ã®", "ãŸã‚", "ã‚ˆã†", "ã¨ã", 
        "ã¨ã“ã‚", "ã¿ãŸã„", "ã™ã‚‹", "ãªã‚‹", "ã‚ã‚‹", "ã„ã‚‹", "ã§ãã‚‹",
        "ã•ã‚“", "ã¤", "ã®", "è¨˜äº‹", "ç´¹ä»‹", "è§£èª¬", "ã¾ã¨ã‚", "æ–¹æ³•",
        "å ´åˆ", "ç†ç”±", "è©±", "å†…å®¹", "çµæœ", "æƒ…å ±", "ã‚µãƒ¼ãƒ“ã‚¹",
        # æ›–æ˜§ãªèª
        "ãŸã¡", "å¯èƒ½", "ã‚µã‚¤ãƒˆ", "ãƒ–ãƒ­ã‚°", "ã‚¨ãƒ³ãƒˆãƒª", "æŠ•ç¨¿",
        "ä¸–ç•Œ", "ä»Šå›", "æœ€è¿‘", "è‡ªåˆ†", "ã¿ã‚“ãª", "äºº", "æ–¹",
        # ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ åï¼ˆQiitaãªã©é™¤å¤–ã—ãŸã„å ´åˆï¼‰
        "Qiita", "BLOG", "ãƒ–ãƒ­ã‚°"
    }
    
    print("\nğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºä¸­...\n")
    
    for article in articles:
        title = article.get("title", "")
        
        # å½¢æ…‹ç´ è§£æ
        for token in tokenizer.tokenize(title):
            # ãƒˆãƒ¼ã‚¯ãƒ³æƒ…å ±ã‚’åˆ†å‰²
            parts = str(token).split("\t")
            if len(parts) >= 2:
                word = parts[0]  # å˜èª
                pos = parts[1].split(",")[0]  # å“è©
                
                # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¡ä»¶
                # 1. åè©ã§ã‚ã‚‹ã“ã¨
                # 2. 2æ–‡å­—ä»¥ä¸Š
                # 3. ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ã§ãªã„
                # 4. æ•°å­—ã ã‘ã§ã¯ãªã„
                # 5. è¨˜å·ã‚’å«ã¾ãªã„
                if (pos == "åè©" and 
                    len(word) >= 2 and 
                    word not in stop_words and
                    not word.isdigit() and
                    not re.search(r'[!-/:-@[-`{-~]', word)):
                    keywords.append(word)
    
    return keywords

def analyze_trending_words(keywords, top_n=15):
    """
    é »å‡ºãƒ¯ãƒ¼ãƒ‰ã‚’ã‚«ã‚¦ãƒ³ãƒˆã—ã¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°åŒ–
    """
    counter = Counter(keywords)
    ranking = counter.most_common(top_n)
    
    print(f"ğŸ”¥ğŸ”¥ğŸ”¥ æ€¥ä¸Šæ˜‡ãƒ¯ãƒ¼ãƒ‰ TOP{top_n} ğŸ”¥ğŸ”¥ğŸ”¥\n")
    print("-" * 50)
    
    if not ranking:
        print("âš ï¸  ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return []
    
    for rank, (word, count) in enumerate(ranking, 1):
        # ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«çš„ã«è¦‹ã‚„ã™ã
        bar = "â–ˆ" * count
        print(f"{rank:2d}ä½: {word:20s} {bar} ({count}å›)")
    
    print("-" * 50)
    
    return ranking

def save_trending_words(ranking, filename="trending_words.json"):
    """
    æ€¥ä¸Šæ˜‡ãƒ¯ãƒ¼ãƒ‰ã‚’JSONã§ä¿å­˜
    """
    data = [{"rank": i+1, "word": word, "count": count} 
            for i, (word, count) in enumerate(ranking)]
    
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… {filename} ã«ä¿å­˜ã—ã¾ã—ãŸï¼")

def analyze_from_json(json_filename="hatena_ranking.json", top_n=15):
    """
    JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚“ã§åˆ†æï¼ˆå¤–éƒ¨ã‹ã‚‰å‘¼ã³å‡ºã—ç”¨ï¼‰
    """
    print("\n" + "=" * 50)
    print("ğŸ“Š æ€¥ä¸Šæ˜‡ãƒ¯ãƒ¼ãƒ‰åˆ†æé–‹å§‹")
    print("=" * 50)
    
    # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    articles = load_json(json_filename)
    
    if not articles:
        print("âš ï¸  ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return []
    
    print(f"\nğŸ“š {len(articles)}ä»¶ã®è¨˜äº‹ã‚’åˆ†æã—ã¾ã™")
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
    keywords = extract_keywords(articles)
    
    print(f"âœ… {len(keywords)}å€‹ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºã—ã¾ã—ãŸ\n")
    
    # æ€¥ä¸Šæ˜‡ãƒ¯ãƒ¼ãƒ‰ãƒ©ãƒ³ã‚­ãƒ³ã‚°
    ranking = analyze_trending_words(keywords, top_n=top_n)
    
    # JSONã«ä¿å­˜
    if ranking:
        save_trending_words(ranking)
    
    print("\nğŸ‰ åˆ†æå®Œäº†ï¼\n")
    
    return ranking

def main():
    """
    å˜ä½“å®Ÿè¡Œç”¨ã®ãƒ¡ã‚¤ãƒ³å‡¦ç†
    """
    analyze_from_json()

if __name__ == "__main__":
    main()